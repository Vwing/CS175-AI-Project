{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "import nltk\n",
    "\n",
    "NAME = \"fleep\"\n",
    "GENDER = \"M\"\n",
    "CLASS = \"hunter\"\n",
    "RACE = \"dwarf\"\n",
    "\n",
    "quests = pd.read_csv(\"quests.csv\")\n",
    "#print(list(quests.columns.values))\n",
    "details = quests.Details\n",
    "rawStr = \"\"\n",
    "for d in details:\n",
    "    rawStr += str(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepositions = [\"were\",\"of\",\"the\",\"from\",\"is\",\"on\",\"when\",\"at\",\"for\",\n",
    "               \"are\", \"to\", \"we\", \"a\", \"who\", \"i\", \"he\", \"she\", \"in\",\n",
    "               \"her\",\"his\",\"their\",\"they\", \"but\", \"however\", \"therefore\",\n",
    "               \"that\", \"has\", \"with\"] #words we don't want to end a sentence with\n",
    "def get_ran_word(cfdist,word,myinterest):\n",
    "    if myinterest in cfdist[word].keys() and random.random() > 0.1 and myinterest is not word:\n",
    "        return myinterest\n",
    "    if \".\" in cfdist[word].keys() and random.random() > 0.5 and word not in prepositions:\n",
    "        return \".\"\n",
    "    d = copy.copy(cfdist[word])\n",
    "    lend = len(d)\n",
    "    if lend == 0:\n",
    "        return random.choice([\"the\",\"of\"])\n",
    "    if lend > 10:\n",
    "        sampleNum = lend // 5; #sample from the top 20% words\n",
    "    else:\n",
    "        sampleNum = lend\n",
    "    words = []\n",
    "    for i in range(sampleNum):\n",
    "        if(lend == 1):\n",
    "            words.append(d.keys()[0])\n",
    "            break;\n",
    "        words.append(d.max());\n",
    "        del(d[words[i]]);\n",
    "    return random.choice(words)\n",
    "\n",
    "def generate_ran_sentence(cfdist, initwords, interest=\"\", minwords=5, maxwords = 15):#, num=15):\n",
    "    i = 1\n",
    "    interestCount = 0\n",
    "    foundInterest = False\n",
    "    words = [initwords.capitalize()]\n",
    "    word = get_ran_word(cfdist,initwords.split(\" \")[-1],interest)\n",
    "    while word is not \".\" and i < maxwords:\n",
    "        words.append(word)\n",
    "        if foundInterest: #it has become uninteresting...\n",
    "            word = get_ran_word(cfdist,word,\"\")\n",
    "        else:\n",
    "            word = get_ran_word(cfdist,word,interest)\n",
    "        if word is interest:\n",
    "            foundInterest = True\n",
    "    if not foundInterest or len(words) < minwords: #keep going til you get an interest\n",
    "        return generate_ran_sentence(cfdist,initwords,interest=interest,minwords=minwords,maxwords=maxwords)\n",
    "    return words\n",
    "        \n",
    "def format_simple(document):\n",
    "    doc = document.lower()                                           #convert to lower case\n",
    "    doc = re.sub(r'[\\?\\{\\}\\[\\]\\|\\(\\)!,:\\-;\\$\\\"<>]',' ',doc)           #remove punctuations\n",
    "    doc = re.sub(r'[\\']','',doc)                                     # remove appostrophes\n",
    "    doc = re.sub(r'\\.', ' . ', doc)                                  #add spaces between periods\n",
    "    doc = re.sub(r'[\\s]+',' ', doc)                                  #remove whitespace clumps\n",
    "    doc =  doc.strip()                                               #remove trailing whitespace\n",
    "    return doc\n",
    "\n",
    "def replace_variables(document):\n",
    "    doc = document.lower()\n",
    "    if GENDER == \"M\":\n",
    "        doc = re.sub(r'\\$g(.*):(.*);',r'\\g<1>',doc)\n",
    "    else:\n",
    "        doc = re.sub(r'\\$g(.*):(.*);',r'\\g<2>',doc)\n",
    "    doc = re.sub(r'\\$c',CLASS,doc)\n",
    "    doc = re.sub(r'\\$n',NAME,doc)\n",
    "    doc = re.sub(r'\\$r',RACE,doc)\n",
    "    return doc\n",
    "    \n",
    "def format_simple_keep_punctuation(document):\n",
    "    doc = document.lower()                                           #convert to lower case\n",
    "    doc = re.sub(r'[\\[\\]\\|<>\\-]','',doc)                                  #remove unneeded punctuations\n",
    "    doc = re.sub(r'([\\.\\?\\{\\}\\[\\]\\(\\)!,:\\-;\\$\\\"\\'])',r' \\g<1> ',doc)           #put spaces between tagged punctuations\n",
    "    doc = re.sub(r'[\\s]+',' ', doc)                                  #remove whitespace clumps\n",
    "    doc =  doc.strip()                                               #remove trailing whitespace\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rawStr = replace_variables(rawStr)\n",
    "# rawStr = format_simple_keep_punctuation(rawStr)\n",
    "# tokens = rawStr.split(' ')\n",
    "# text = nltk.Text(tokens)\n",
    "\n",
    "alldeets = \"\".join(str(d) for d in details)\n",
    "alldeets = replace_variables(alldeets)\n",
    "#construct text_nopunct\n",
    "rawStr = format_simple(alldeets)\n",
    "tokens_nopunct = rawStr.split(' ')\n",
    "text_nopunct = nltk.Text(tokens_nopunct)\n",
    "#construct text (with punctuation)\n",
    "rawStr = format_simple_keep_punctuation(alldeets)\n",
    "tokens = rawStr.split(' ')\n",
    "text = nltk.Text(tokens_nopunct)\n",
    "\n",
    "# get cfds from bigrams\n",
    "bigrams_nopunct = nltk.bigrams(text_nopunct)\n",
    "cfd_nopunct = nltk.ConditionalFreqDist(bigrams_nopunct)\n",
    "\n",
    "bigrams = nltk.bigrams(text)\n",
    "cfd = nltk.ConditionalFreqDist(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "postag = nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The humans have spoken in stormwind. The orcs and realize that stormwind. The world is entitled to stormwind keep. A new beginning to sponsor you into stormwind guard. Return to the stormwind is hard to stormwind.\n",
      "\n",
      "The humans go and valor and worse the harpy named iverron as these blood. The orcs emerging from southern duskwood as he carries the harpy wenches to report from which. The world is causing the harpy named in dire. A new beginning ive a harpy wenches will all levels at scourgeholme now its energy. Return to the harpy named sidragos which the harpy nesting.\n",
      "\n",
      "The humans have water supply our hunters of twenty. The orcs of water elementals at him return. The world is water well it with water. A new beginning and water on da south through them. Return to the water on bloodmyst when the water.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#uses bigram frequencies to generate random sentences of a common theme\n",
    "def get_paragraph(startwords,interest):\n",
    "    numsentences = len(startwords)\n",
    "    interests = [interest]*numsentences\n",
    "    sentences = []\n",
    "    randsents = []\n",
    "    for j,k in zip(startwords,interests):\n",
    "        randsents.append(generate_ran_sentence(cfd_nopunct, j,interest=k,maxwords=20))\n",
    "    for sents in randsents:\n",
    "        sentences.append(\" \".join(sents))\n",
    "    return (\". \".join(sentences) + \".\")\n",
    "        \n",
    "startwords = [\"the humans\",\"the orcs\", \"the world is\",\"a new beginning\", \"return to the\"]\n",
    "interests = [\"stormwind\",\"harpy\",\"water\"]\n",
    "for interest in interests:\n",
    "    print(get_paragraph(startwords,interest))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Travel to moonwell And Kill zulmarosh The zulaman\n",
      "Journey to khan And Kill 5 compound\n",
      "Travel to jabber And Slay xoroth The zin\n",
      "Travel to zin And Slay youve The zin\n",
      "Gather 5 diet arakkoa Located In zulmarosh\n",
      "Find 1 large duty Located In yer\n",
      "Journey to kreldig And Slay xoroth The jibber\n",
      "Find 10 large dem At youve\n",
      "Journey to zulmarosh And Slay 1 energy\n",
      "Travel to korkron And Slay youve The khan\n"
     ]
    }
   ],
   "source": [
    "from nltk import PCFG\n",
    "from nltk.parse.generate import generate, demo_grammar\n",
    "from nltk import CFG\n",
    "from operator import itemgetter\n",
    "from random import shuffle\n",
    "\n",
    "nonterms = {\".\",\",\",r\"PRP$\",\":\",\"$\",\"\\'\\'\", \"(\", \")\", \"CC\", \"CD\", \"DT\", \"EX\", \"FW\", \"IN\", r\"WP$\"}\n",
    "nonpos = {\"i\", \"\\\"\", \"\\'\"}\n",
    "termvalues = {}\n",
    "#test = {\"NN\",\"JJ\",\"JJR\",\"MD\",\"RB\",\"VB\",\"RBS\",\"RBR\",\"UH\", \"VBP\", \"VBZ\", \"WDT\", \"CC\", \"NNS\", \"PRP\", \"VBN\", \"EX\"}\n",
    "\n",
    "limit = 30\n",
    "postags = postag\n",
    "shuffle(postags)\n",
    "postags.sort(key=itemgetter(1))\n",
    "my_grammar = \"\"\"\n",
    "  S -> KI NK\n",
    "  S -> COLCD N\n",
    "  S -> TR NT\n",
    "  S -> TK\n",
    "  COLCD -> COL CD\n",
    "  TK -> RT TO AND TAL TO NNP\n",
    "  TK -> TR TO AND TAL TO NNP\n",
    "  NK -> CD NN AT NNP\n",
    "  NK -> NNP THE NNP\n",
    "  NT -> TO NNP\n",
    "  NT -> TO NNP AND KI CD NN\n",
    "  NT -> TO NNP AND COL CD NN\n",
    "  NT -> TO NNP AND KI NNP THE NNP\n",
    "  N -> JJ NN FR NNP\n",
    "  N -> JJ NN AT NNP\n",
    "  N -> JJ NN\n",
    "  N -> NN\n",
    "  COL -> 'Collect' | 'Gather' | 'Find'\n",
    "  FR -> 'from'\n",
    "  KI -> 'Kill' | 'Slay'\n",
    "  TR -> 'Travel' | 'Journey'\n",
    "  AT -> 'At' | 'Located In'\n",
    "  THE -> 'The'\n",
    "  OF -> 'Of'\n",
    "  AND -> 'And'\n",
    "  RT -> 'Return'\n",
    "  TAL -> 'Talk'\n",
    "\"\"\"\n",
    "\n",
    "my_grammar += \"  \" + \"\\n  \".join([(r\"CD -> '\" + str(num) + r\"'\") for num in [1,5,10]])\n",
    "for (a,b) in postags:\n",
    "    if b not in nonterms and a not in nonpos and len(a)>1:\n",
    "        if termvalues.has_key(b) == False:\n",
    "            termvalues[b] = 1\n",
    "            my_grammar += \"\\n  \" + \"\\n  \".join([(b + r\" -> '\" + a + r\"'\")])\n",
    "        elif termvalues.get(b) < limit:\n",
    "            termvalues[b] += 1\n",
    "            my_grammar += \"\\n  \" + \"\\n  \".join([(b + r\" -> '\" + a + r\"'\")]) \n",
    "\n",
    "grammar = CFG.fromstring(my_grammar)\n",
    "fulllist = []\n",
    "for sentence in generate(grammar):\n",
    "    fulllist.append(sentence)\n",
    "\n",
    "ranlist = [None]*10\n",
    "for i in range(0,10):\n",
    "    ranlist[i] = random.choice(fulllist)\n",
    "\n",
    "for sentence in ranlist:\n",
    "    print(' '.join(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
